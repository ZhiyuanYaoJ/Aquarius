{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from math import pi\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "utils_dir = '../../src/utils'\n",
    "sys.path.insert(0, utils_dir) # add utils dir to path\n",
    "import testbed_utils as tu\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler, RobustScaler\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_style({\"xtick.direction\": \"in\",\"ytick.direction\": \"in\",\"xtick.top\":True,\"ytick.right\":True,\"axes.grid\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the MACROs here\n",
    "EXPERIMENT = 'atc-classification'\n",
    "DATA_DIR = '../../data/{}'.format(EXPERIMENT)\n",
    "USER = 'yzy'\n",
    "GLOBAL_CONF = tu.common.json_read_file('../../config/global_conf.json')\n",
    "ROOT_DIR = GLOBAL_CONF['dir']['root']\n",
    "# local machine hostname\n",
    "# LOCAL_MACHINE = LOCAL_MACHINE[0]\n",
    "LOCAL_MACHINE = '10.60.16.17'\n",
    "SERVER_IPS = GLOBAL_CONF['net']['physical_server_ip']\n",
    "# local machine ID\n",
    "LOCAL_ID = SERVER_IPS.index(LOCAL_MACHINE)\n",
    "REMOTE_IDS = [i for i, v in enumerate(SERVER_IPS) if v != LOCAL_MACHINE]\n",
    "SHM_LAYOUT = tu.common.json_read_file(\"../../src/lb/dev/shm_layout_base.json\")\n",
    "FEATURE_AS_CNT = [_[1] for _ in SHM_LAYOUT[\"vpp\"][\"struct\"][\"as_stat\"][1:]] # counter features gathered for each AS in as_stat_t\n",
    "FEATURE_AS_RES = [_[1] for _ in SHM_LAYOUT[\"vpp\"][\"struct\"][\"reservoir_as\"]] # features gathered for each AS w/ reservoir sampling\n",
    "RES_FEATURE_ENG = [\"avg\", \"90\", \"std\", \"avg_decay\", \"90_decay\"]\n",
    "FEATURE_AS_ALL = FEATURE_AS_CNT + [\"_\".join((a, b)) for a in FEATURE_AS_RES for b in RES_FEATURE_ENG]\n",
    "GT = [\"cpu\", \"memory\", \"apache\", \"asid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(\n",
    "    lb_method = 'aquarius_ecmp',\n",
    "    trace='wiki',\n",
    "    experiment='offline',\n",
    "    sample='hour0.csv',\n",
    "    from_orig=False,\n",
    "    config_file_prefix='1lb-36core',\n",
    "    clip_n=20000,\n",
    "    n_episode=1,\n",
    "    episode_base=0,\n",
    "    remote_servers=[0, 2, 3],\n",
    "    clt_server=0,\n",
    "    lb_gather_usage=False,\n",
    "):\n",
    "    '''\n",
    "    @brief: run a set of experiments with a specific setup\n",
    "    @params:\n",
    "        lb_method: method name defined in config/lb_methods.json\n",
    "        trace: trace type as in data/trace/*\n",
    "    '''\n",
    "    global USER, ROOT_DIR, LOCAL_ID, REMOTE_IDS, SERVER_IPS\n",
    "    assert set(remote_servers) - set(REMOTE_IDS) == set()\n",
    "    config_file = config_file_prefix+'-'+str(LOCAL_ID)\n",
    "    config_file_remote = {i: config_file_prefix+'-{}'.format(i) for i in REMOTE_IDS}\n",
    "\n",
    "    for episode in range(episode_base, episode_base+n_episode):\n",
    "    \n",
    "        task_name, task_dir, nodes = tu.init_task_info(\n",
    "            experiment=experiment,\n",
    "            lb_method=lb_method,\n",
    "            trace=trace,\n",
    "            sample=sample,\n",
    "            cluster_config=config_file+'.json',\n",
    "            alias=config_file_prefix,\n",
    "        )\n",
    "\n",
    "        print(\">> run task {} - episode {}\".format(task_name, episode))\n",
    "\n",
    "        #--- spin up ---#\n",
    "        for server_id in remote_servers:\n",
    "            if clip_n and server_id == 0:\n",
    "                clip_n_option = ' -n {}'.format(clip_n)\n",
    "            else:\n",
    "                clip_n_option = ''\n",
    "\n",
    "            cmd = 'ssh -t {}@{} \"python3 {}/src/utils/run_server.py --experiment {} -m {} --tr {} --sample {} -f {}.json{}\"'.format(\n",
    "                USER, SERVER_IPS[server_id], ROOT_DIR, experiment, lb_method, trace, sample, config_file_remote[server_id], clip_n_option)\n",
    "\n",
    "            tu.subprocess.Popen(cmd, shell=True)\n",
    "        \n",
    "\n",
    "        tu.prepare_img(lb_method=lb_method, from_orig=from_orig, debug_node=False)\n",
    "\n",
    "        tu.runall()\n",
    "        time.sleep(10)\n",
    "        \n",
    "        #--- check network ---#\n",
    "\n",
    "        net_ok = False\n",
    "        while not net_ok:\n",
    "            try:\n",
    "                tu.gt_socket_check()\n",
    "                net_ok = True\n",
    "            except:\n",
    "                print('error')\n",
    "                time.sleep(1)\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        # start gathering at LB node\n",
    "        for lb in tu.NODES['lb']:\n",
    "            lb.run_init_bg()\n",
    "            if lb_gather_usage:\n",
    "                lb.gather_usage()\n",
    "\n",
    "        # run traffic\n",
    "        t0 = time.time()\n",
    "        cmd = 'ssh -t {}@{} \"python3 {}/src/utils/run_traffic.py --experiment {} -m {} --tr {} --sample {} -f {}.json\"'.format(\n",
    "            USER, SERVER_IPS[clt_server], ROOT_DIR, experiment, lb_method, trace, sample, config_file_remote[0])\n",
    "        tu.subprocess_cmd(cmd)\n",
    "        print(\"Trace replay over w/ total time: {:.3f}s\".format(time.time()-t0))\n",
    "        time.sleep(5)\n",
    "\n",
    "        # fetch results from nodes\n",
    "        for server_id in remote_servers:\n",
    "            cmd = 'ssh -t {}@{} \"python3 {}/src/utils/shutdown_server.py --experiment {} -m {} --tr {} --sample {} -f {}.json --episode {}\"'.format(\n",
    "                USER, SERVER_IPS[server_id], ROOT_DIR, experiment, lb_method, trace, sample, config_file_remote[server_id], episode)\n",
    "            tu.subprocess.Popen(cmd, shell=True)\n",
    "\n",
    "        for lb in tu.NODES['lb']:\n",
    "            lb.fetch_result(task_dir, episode)\n",
    "\n",
    "        tu.shutall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'aquarius_ecmp'\n",
    "samples = ['hour{}.csv'.format(i) for i in [8, 12]]\n",
    "config_prefix = ['conf0{}'.format(i) for i in [1]]\n",
    "trace = 'wiki'\n",
    "from_orig=None\n",
    "clip_n = 200000\n",
    "n_episode = 2\n",
    "episode_base = 0\n",
    "remote_servers = [0]\n",
    "clt_server = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_method=method\n",
    "trace=trace\n",
    "experiment=EXPERIMENT\n",
    "sample=samples[0]\n",
    "from_orig=from_orig\n",
    "config_file_prefix=config_prefix[0]\n",
    "clip_n=clip_n\n",
    "n_episode=n_episode\n",
    "episode_base=episode_base\n",
    "remote_servers=remote_servers\n",
    "clt_server=clt_server\n",
    "lb_gather_usage=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(remote_servers) - set(REMOTE_IDS) == set()\n",
    "config_file = config_file_prefix+'-'+str(LOCAL_ID)\n",
    "config_file_remote = {i: config_file_prefix+'-{}'.format(i) for i in REMOTE_IDS}\n",
    "\n",
    "episode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> run task wiki-aquarius_ecmp-hour8-conf01 - episode 0\n"
     ]
    }
   ],
   "source": [
    "task_name, task_dir, nodes = tu.init_task_info(\n",
    "    experiment=experiment,\n",
    "    lb_method=lb_method,\n",
    "    trace=trace,\n",
    "    sample=sample,\n",
    "    cluster_config=config_file+'.json',\n",
    "    alias=config_file_prefix,\n",
    ")\n",
    "\n",
    "print(\">> run task {} - episode {}\".format(task_name, episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh -t yzy@10.60.16.12 \"python3 /home/yzy/aquarius/src/utils/run_server.py --experiment atc-classification -m aquarius_ecmp --tr wiki --sample hour8.csv -f conf01-0.json -n 200000\"\n"
     ]
    }
   ],
   "source": [
    "#--- spin up ---#\n",
    "for server_id in remote_servers:\n",
    "    if clip_n and server_id == 0:\n",
    "        clip_n_option = ' -n {}'.format(clip_n)\n",
    "    else:\n",
    "        clip_n_option = ''\n",
    "\n",
    "    cmd = 'ssh -t {}@{} \"python3 {}/src/utils/run_server.py --experiment {} -m {} --tr {} --sample {} -f {}.json{}\"'.format(\n",
    "        USER, SERVER_IPS[server_id], ROOT_DIR, experiment, lb_method, trace, sample, config_file_remote[server_id], clip_n_option)\n",
    "\n",
    "    print(cmd)\n",
    "    tu.subprocess.Popen(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base img for aquarius_ecmp does not exist, create one...\n",
      "node_lb_0 ready: ssh -p 8900 cisco@localhost\n",
      "node_lb_1 ready: ssh -p 8901 cisco@localhost\n",
      "node_server_0 ready: ssh -p 9000 cisco@localhost\n",
      "node_server_1 ready: ssh -p 9001 cisco@localhost\n",
      "node_server_2 ready: ssh -p 9002 cisco@localhost\n",
      "node_server_3 ready: ssh -p 9003 cisco@localhost\n",
      "node_server_4 ready: ssh -p 9004 cisco@localhost\n",
      "node_server_5 ready: ssh -p 9005 cisco@localhost\n",
      "node_server_6 ready: ssh -p 9006 cisco@localhost\n"
     ]
    }
   ],
   "source": [
    "tu.prepare_img(lb_method=lb_method, from_orig=from_orig, debug_node=False)\n",
    "\n",
    "tu.runall()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LB Node 0: pass\n",
      "LB Node 1: pass\n"
     ]
    }
   ],
   "source": [
    "#--- check network ---#\n",
    "\n",
    "net_ok = False\n",
    "while not net_ok:\n",
    "    try:\n",
    "        tu.gt_socket_check()\n",
    "        net_ok = True\n",
    "    except:\n",
    "        print('error')\n",
    "        time.sleep(1)\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start gathering at LB node\n",
    "for lb in tu.NODES['lb']:\n",
    "    lb.run_init_bg()\n",
    "    if lb_gather_usage:\n",
    "        lb.gather_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6e49d02075cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m cmd = 'ssh -t {}@{} \"python3 {}/src/utils/run_traffic.py --experiment {} -m {} --tr {} --sample {} -f {}.json\"'.format(\n\u001b[1;32m      4\u001b[0m     USER, SERVER_IPS[clt_server], ROOT_DIR, experiment, lb_method, trace, sample, config_file_remote[0])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubprocess_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trace replay over w/ total time: {:.3f}s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aquarius/src/utils/testbed_utils.py\u001b[0m in \u001b[0;36msubprocess_cmd\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m     51\u001b[0m     '''\n\u001b[1;32m     52\u001b[0m     \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mproc_stdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc_stdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lb/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    924\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run traffic\n",
    "t0 = time.time()\n",
    "cmd = 'ssh -t {}@{} \"python3 {}/src/utils/run_traffic.py --experiment {} -m {} --tr {} --sample {} -f {}.json\"'.format(\n",
    "    USER, SERVER_IPS[clt_server], ROOT_DIR, experiment, lb_method, trace, sample, config_file_remote[0])\n",
    "tu.subprocess_cmd(cmd)\n",
    "print(\"Trace replay over w/ total time: {:.3f}s\".format(time.time()-t0))\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch results from nodes\n",
    "for server_id in remote_servers:\n",
    "    cmd = 'ssh -t {}@{} \"python3 {}/src/utils/shutdown_server.py --experiment {} -m {} --tr {} --sample {} -f {}.json --episode {}\"'.format(\n",
    "        USER, SERVER_IPS[server_id], ROOT_DIR, experiment, lb_method, trace, sample, config_file_remote[server_id], episode)\n",
    "    tu.subprocess.Popen(cmd, shell=True)\n",
    "\n",
    "for lb in tu.NODES['lb']:\n",
    "    lb.fetch_result(task_dir, episode)\n",
    "\n",
    "tu.shutall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssh -t yzy@10.60.16.12 \"python3 /home/yzy/aquarius/src/utils/shutdown_server.py --experiment atc-classification -m aquarius_ecmp --tr wiki --sample hour8.csv -f conf01-0.json --episode 0\"'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (lb)",
   "language": "python",
   "name": "lb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
